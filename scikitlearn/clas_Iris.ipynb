{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42c2f7f",
   "metadata": {},
   "source": [
    "# Ejemplo Completo: Clasificaci√≥n Supervisada\n",
    "## Clasificaci√≥n de Especies de Flores Iris\n",
    "\n",
    "### Objetivo\n",
    "Clasificar flores Iris en tres especies diferentes bas√°ndose en medidas de p√©talos y s√©palos.\n",
    "\n",
    "### Conceptos que aprender√°s:\n",
    "- Trabajar con datasets reales incluidos en Scikit-Learn\n",
    "- Implementar clasificaci√≥n con Random Forest\n",
    "- Evaluar clasificadores (accuracy, precision, recall, F1)\n",
    "- Interpretar matrices de confusi√≥n\n",
    "- Analizar importancia de caracter√≠sticas\n",
    "- Calcular probabilidades de predicci√≥n\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7422b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuraci√≥n para gr√°ficos\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a57349",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Cargar y Explorar el Dataset\n",
    "\n",
    "El dataset Iris es uno de los m√°s famosos en Machine Learning. Contiene medidas de 150 flores de 3 especies diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc2e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset cl√°sico de Iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Estructura del dataset\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET IRIS - INFORMACI√ìN GENERAL\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDescripci√≥n: {iris.DESCR[:200]}...\")\n",
    "print(f\"\\nN√∫mero de muestras: {iris.data.shape[0]}\")\n",
    "print(f\"N√∫mero de caracter√≠sticas: {iris.data.shape[1]}\")\n",
    "print(f\"Clases: {iris.target_names}\")\n",
    "print(f\"Nombres de caracter√≠sticas: {iris.feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bebf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame para mejor visualizaci√≥n\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['especie'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PRIMERAS 10 FILAS DEL DATASET\")\n",
    "print(\"=\" * 70)\n",
    "print(df.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"√öLTIMAS 10 FILAS DEL DATASET\")\n",
    "print(\"=\" * 70)\n",
    "print(df.tail(10))\n",
    "\n",
    "# Guardar el dataset en un archivo CSV\n",
    "# df.to_csv('iris_dataset.csv', index=False)\n",
    "print(\"\\nEl dataset se ha guardado en 'iris_dataset.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f61fd09",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. An√°lisis Exploratorio de Datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ESTAD√çSTICAS DESCRIPTIVAS\")\n",
    "print(\"=\" * 70)\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DISTRIBUCI√ìN DE CLASES\")\n",
    "print(\"=\" * 70)\n",
    "print(df['especie'].value_counts())\n",
    "print(f\"\\nDataset balanceado: {df['especie'].value_counts().nunique() == 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82437895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de la distribuci√≥n de clases\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['especie'].value_counts().plot(kind='bar', color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "plt.title('Distribuci√≥n de Especies de Iris', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Especie')\n",
    "plt.ylabel('Cantidad de Muestras')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bacd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de caracter√≠sticas por especie\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "caracteristicas = iris.feature_names\n",
    "for idx, feature in enumerate(caracteristicas):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    for especie in iris.target_names:\n",
    "        data = df[df['especie'] == especie][feature]\n",
    "        ax.hist(data, alpha=0.6, label=especie, bins=15)\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Frecuencia')\n",
    "    ax.set_title(f'Distribuci√≥n: {feature}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot para ver relaciones entre caracter√≠sticas\n",
    "print(\"\\nGenerando gr√°fico de relaciones entre caracter√≠sticas...\")\n",
    "sns.pairplot(df, hue='especie', diag_kind='hist', markers=['o', 's', 'D'])\n",
    "plt.suptitle('Relaciones entre Caracter√≠sticas por Especie', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MATRIZ DE CORRELACI√ìN\")\n",
    "print(\"=\" * 70)\n",
    "correlation_matrix = df.drop('especie', axis=1).corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Matriz de Correlaci√≥n entre Caracter√≠sticas')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba096d02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Preparar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar caracter√≠sticas (X) y variable objetivo (y)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PREPARACI√ìN DE DATOS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nForma de X (caracter√≠sticas): {X.shape}\")\n",
    "print(f\"Forma de y (objetivo): {y.shape}\")\n",
    "\n",
    "# Dividir en conjunto de entrenamiento (70%) y prueba (30%)\n",
    "# stratify=y asegura que ambos conjuntos tengan la misma proporci√≥n de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y  # Importante para mantener balance\n",
    ")\n",
    "\n",
    "print(f\"\\nDatos de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Datos de prueba: {X_test.shape[0]} muestras\")\n",
    "print(f\"Proporci√≥n: {X_train.shape[0]/len(X)*100:.1f}% train, {X_test.shape[0]/len(X)*100:.1f}% test\")\n",
    "\n",
    "# Verificar balance en ambos conjuntos\n",
    "print(\"\\nDistribuci√≥n de clases en entrenamiento:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for clase, count in zip(iris.target_names[unique], counts):\n",
    "    print(f\"  {clase}: {count}\")\n",
    "\n",
    "print(\"\\nDistribuci√≥n de clases en prueba:\")\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "for clase, count in zip(iris.target_names[unique], counts):\n",
    "    print(f\"  {clase}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb116e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Escalar las Caracter√≠sticas\n",
    "\n",
    "Importante: Random Forest no requiere escalado, pero lo hacemos para demostrar buenas pr√°cticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar caracter√≠sticas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ESCALADO DE CARACTER√çSTICAS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nEstad√≠sticas ANTES del escalado (conjunto de entrenamiento):\")\n",
    "print(f\"Media: {X_train.mean(axis=0)}\")\n",
    "print(f\"Desviaci√≥n est√°ndar: {X_train.std(axis=0)}\")\n",
    "\n",
    "print(\"\\nEstad√≠sticas DESPU√âS del escalado:\")\n",
    "print(f\"Media: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"Desviaci√≥n est√°ndar: {X_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1e0c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Crear y Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d217753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo de Random Forest\n",
    "modelo_clasificador = RandomForestClassifier(\n",
    "    n_estimators=100,      # N√∫mero de √°rboles\n",
    "    max_depth=5,           # Profundidad m√°xima de cada √°rbol\n",
    "    random_state=42,       # Reproducibilidad\n",
    "    n_jobs=-1              # Usar todos los cores del CPU\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ENTRENAMIENTO DEL MODELO\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Configuraci√≥n del modelo:\")\n",
    "print(f\"  ‚Ä¢ Algoritmo: Random Forest Classifier\")\n",
    "print(f\"  ‚Ä¢ N√∫mero de √°rboles: {modelo_clasificador.n_estimators}\")\n",
    "print(f\"  ‚Ä¢ Profundidad m√°xima: {modelo_clasificador.max_depth}\")\n",
    "print(\"\\nEntrenando modelo...\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo_clasificador.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"‚úì Modelo entrenado exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81ecd9d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Hacer Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = modelo_clasificador.predict(X_test_scaled)\n",
    "\n",
    "# Tambi√©n podemos obtener probabilidades\n",
    "y_pred_proba = modelo_clasificador.predict_proba(X_test_scaled)\n",
    "\n",
    "# Imprimir predicciones con .predict()\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREDICCIONES con .predict()\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nPrimeras 5 predicciones:\")\n",
    "print(\"-\" * 70)\n",
    "for i in range(5):\n",
    "    real = iris.target_names[y_test[i]]\n",
    "    pred = iris.target_names[y_pred[i]]\n",
    "    correcto = \"‚úì\" if real == pred else \"‚úó\"\n",
    "    print(f\"{correcto} Real: {real:15s} | Predicho: {pred:15s}\")\n",
    "\n",
    "\n",
    "# Imprimir predicciones con .predict_proba()\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREDICCIONES con .predict_proba()\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nPrimeras 5 predicciones con probabilidades:\")\n",
    "print(\"-\" * 70)\n",
    "for i in range(5):\n",
    "    real = iris.target_names[y_test[i]]\n",
    "    proba = y_pred_proba[i]\n",
    "    proba_str = \", \".join([f\"{iris.target_names[j]}: {p:.2f}\" for j, p in enumerate(proba)])\n",
    "    print(f\"Real: {real:15s} | Probabilidades: {proba_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad72af3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Evaluar el Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4631da5a",
   "metadata": {},
   "source": [
    "### M√©tricas de evaluaci√≥n para clasificaci√≥n\n",
    "\n",
    "- **Accuracy**: Proporci√≥n de predicciones correctas sobre el total de muestras.\n",
    "- **Precision**: Proporci√≥n de verdaderos positivos entre todos los positivos predichos.\n",
    "- **Recall**: Proporci√≥n de verdaderos positivos entre todos los positivos reales.\n",
    "- **F1-Score**: Promedio arm√≥nico entre precisi√≥n y recall, √∫til en clases desbalanceadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716904f",
   "metadata": {},
   "source": [
    "#### ¬øQu√© es el F1-Score?\n",
    "\n",
    "El **F1-Score** es una m√©trica que combina precisi√≥n y recall en un solo valor. Es especialmente √∫til cuando las clases est√°n desbalanceadas o cuando los falsos positivos y falsos negativos tienen distinto impacto.\n",
    "\n",
    "Se calcula como el promedio arm√≥nico entre precisi√≥n y recall:\n",
    "\n",
    "$$\n",
    "F1 = 2 \\cdot \\frac{\\text{Precisi√≥n} \\cdot \\text{Recall}}{\\text{Precisi√≥n} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "### Rango del F1-Score\n",
    "\n",
    "El **F1-Score** var√≠a entre **0 y 1**:\n",
    "\n",
    "- **F1 = 1**: rendimiento perfecto (precisi√≥n y recall son ambos 1).\n",
    "- **F1 = 0**: el modelo no detect√≥ ning√∫n positivo correctamente.\n",
    "\n",
    "Este valor refleja el **balance entre precisi√≥n y recall**. Si uno de los dos es bajo, el F1 tambi√©n ser√° bajo, incluso si el otro es alto.\n",
    "\n",
    "\n",
    "\n",
    "### ¬øPor qu√© usar F1?\n",
    "\n",
    "- Penaliza los desequilibrios entre precisi√≥n y recall.\n",
    "- Es m√°s conservador que el promedio aritm√©tico.\n",
    "- Ideal cuando se necesita un balance entre detectar correctamente y evitar errores.\n",
    "\n",
    "### Ejemplo\n",
    "\n",
    "Si un modelo tiene:\n",
    "- Precisi√≥n = 0.9\n",
    "- Recall = 0.6\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$\n",
    "F1 = 2 \\cdot \\frac{0.9 \\cdot 0.6}{0.9 + 0.6} = 0.72\n",
    "$$\n",
    "\n",
    "Aunque la precisi√≥n es alta, el F1 baja porque el recall es bajo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df26b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular m√©tricas principales\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESULTADOS DEL MODELO\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nExactitud (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precisi√≥n (Precision): {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"INTERPRETACI√ìN:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"‚Ä¢ De cada 100 predicciones, {accuracy*100:.0f} son correctas\")\n",
    "if accuracy > 0.95:\n",
    "    print(\"  ‚Üí Excelente rendimiento del modelo\")\n",
    "elif accuracy > 0.85:\n",
    "    print(\"  ‚Üí Muy buen rendimiento del modelo\")\n",
    "elif accuracy > 0.75:\n",
    "    print(\"  ‚Üí Buen rendimiento del modelo\")\n",
    "else:\n",
    "    print(\"  ‚Üí El modelo necesita mejoras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab3e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte de clasificaci√≥n detallado\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"REPORTE DE CLASIFICACI√ìN DETALLADO\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"EXPLICACI√ìN DE M√âTRICAS:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"‚Ä¢ Precision: De las predicciones de una clase, cu√°ntas son correctas\")\n",
    "print(\"‚Ä¢ Recall: De todos los casos reales de una clase, cu√°ntos detectamos\")\n",
    "print(\"‚Ä¢ F1-Score: Media arm√≥nica entre precision y recall\")\n",
    "print(\"‚Ä¢ Support: N√∫mero de muestras reales de cada clase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa0c13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Matriz de Confusi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MATRIZ DE CONFUSI√ìN\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nMatriz (valores absolutos):\")\n",
    "print(cm)\n",
    "\n",
    "# Visualizar matriz de confusi√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matriz con valores absolutos\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)\n",
    "disp1.plot(ax=axes[0], cmap='Blues', values_format='d')\n",
    "axes[0].set_title('Matriz de Confusi√≥n (Valores Absolutos)', fontweight='bold')\n",
    "\n",
    "# Matriz normalizada (porcentajes)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=iris.target_names)\n",
    "disp2.plot(ax=axes[1], cmap='Blues', values_format='.2%')\n",
    "axes[1].set_title('Matriz de Confusi√≥n (Normalizada)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"INTERPRETACI√ìN DE LA MATRIZ:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"‚Ä¢ Diagonal principal: Predicciones correctas\")\n",
    "print(\"‚Ä¢ Fuera de la diagonal: Errores de clasificaci√≥n\")\n",
    "print(\"‚Ä¢ Cada fila suma el total de casos reales de esa clase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b03f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Importancia de Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140098c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener importancia de caracter√≠sticas\n",
    "# devuelve un array con valores entre 0 y 1, que suman 1.\n",
    "importancias = modelo_clasificador.feature_importances_\n",
    "\n",
    "# Crear DataFrame para mejor visualizaci√≥n\n",
    "df_importancias = pd.DataFrame({\n",
    "    'caracteristica': iris.feature_names,\n",
    "    'importancia': importancias\n",
    "}).sort_values('importancia', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"IMPORTANCIA DE CARACTER√çSTICAS\")\n",
    "print(\"=\" * 70)\n",
    "print(df_importancias)\n",
    "print(\"\\nCaracter√≠stica m√°s importante:\", df_importancias.iloc[0]['caracteristica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc02bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar importancia de caracter√≠sticas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df_importancias['caracteristica'], df_importancias['importancia'], color='skyblue')\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Importancia de Caracter√≠sticas en el Modelo', fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5bbf17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Predicci√≥n con Nuevas Flores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREDICCI√ìN PARA NUEVAS FLORES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Crear nuevas flores para clasificar\n",
    "nuevas_flores = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],  # Caracter√≠sticas similares a setosa\n",
    "    [6.5, 3.0, 5.5, 1.8],  # Caracter√≠sticas similares a virginica\n",
    "    [5.7, 2.8, 4.1, 1.3]   # Caracter√≠sticas similares a versicolor\n",
    "])\n",
    "\n",
    "# Escalar las nuevas flores\n",
    "nuevas_flores_scaled = scaler.transform(nuevas_flores)\n",
    "\n",
    "# Hacer predicciones\n",
    "predicciones = modelo_clasificador.predict(nuevas_flores_scaled)\n",
    "probabilidades = modelo_clasificador.predict_proba(nuevas_flores_scaled)\n",
    "\n",
    "# Mostrar resultados\n",
    "for i, (flor,pred, probs) in enumerate(zip(nuevas_flores, predicciones, probabilidades), 1):\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"FLOR {i}\")\n",
    "    print('=' * 70)\n",
    "    print(f\"Caracter√≠sticas:\")\n",
    "    for nombre, valor in zip(iris.feature_names, flor):\n",
    "        print(f\"  ‚Ä¢ {nombre}: {valor}\")\n",
    "        print(f\"\\n‚Üí Especie predicha: {iris.target_names[pred]}\")\n",
    "        print(f\"\\nProbabilidades por clase:\")\n",
    "    for nombre, prob in zip(iris.target_names, probs):\n",
    "        barra = '‚ñà' * int(prob * 50)\n",
    "        print(f\"  {nombre:15s}: {prob:.4f} ({prob*100:5.2f}%) {barra}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a7e1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. An√°lisis de Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar casos mal clasificados\n",
    "errores = y_test != y_pred\n",
    "indices_errores = np.where(errores)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"AN√ÅLISIS DE ERRORES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTotal de errores: {errores.sum()} de {len(y_test)} ({errores.sum()/len(y_test)*100:.2f}%)\")\n",
    "\n",
    "if errores.sum() > 0:\n",
    "    print(\"\\nCasos mal clasificados:\")\n",
    "    print(\"-\" * 70)\n",
    "    for idx in indices_errores:\n",
    "        real = iris.target_names[y_test[idx]]\n",
    "        pred = iris.target_names[y_pred[idx]]\n",
    "        print(f\"\\n√çndice {idx}:\")\n",
    "        print(f\"  Real: {real}\")\n",
    "        print(f\"  Predicho: {pred}\")\n",
    "        print(f\"  Caracter√≠sticas: {X_test[idx]}\")\n",
    "        print(f\"  Probabilidades: {y_pred_proba[idx]}\")\n",
    "else:\n",
    "    print(\"\\n¬°Perfecto! El modelo clasific√≥ correctamente todas las muestras.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d029bf3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Validaci√≥n Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccdb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VALIDACI√ìN CRUZADA (5 FOLDS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Realizar validaci√≥n cruzada\n",
    "cv_scores = cross_val_score(\n",
    "    modelo_clasificador, \n",
    "    X_train_scaled, \n",
    "    y_train, \n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"\\nScores por fold:\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f} ({score*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Accuracy promedio: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "print(f\"Rango: [{cv_scores.min():.4f}, {cv_scores.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08259fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validaci√≥n cruzada con m√∫ltiples m√©tricas\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VALIDACI√ìN CRUZADA CON M√öLTIPLES M√âTRICAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "cv_results = cross_validate(\n",
    "    modelo_clasificador,\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=scoring\n",
    ")\n",
    "\n",
    "for metrica in scoring:\n",
    "    scores = cv_results[f'test_{metrica}']\n",
    "    print(f\"\\n{metrica.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Media: {scores.mean():.4f} ¬± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cbfe3b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 14. Comparaci√≥n con Otros Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a58b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARACI√ìN CON OTROS ALGORITMOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Definir varios modelos\n",
    "modelos = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=200)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar cada modelo\n",
    "resultados = []\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    # Entrenar\n",
    "    modelo.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predecir\n",
    "    y_pred_modelo = modelo.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluar\n",
    "    acc = accuracy_score(y_test, y_pred_modelo)\n",
    "    prec = precision_score(y_test, y_pred_modelo, average='weighted')\n",
    "    rec = recall_score(y_test, y_pred_modelo, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred_modelo, average='weighted')\n",
    "    \n",
    "    resultados.append({\n",
    "        'Modelo': nombre,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "df_resultados = pd.DataFrame(resultados).sort_values('Accuracy', ascending=False)\n",
    "print(\"\\n\", df_resultados.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef073c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaci√≥n\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(df_resultados))\n",
    "width = 0.2\n",
    "\n",
    "plt.bar(x - 1.5*width, df_resultados['Accuracy'], width, label='Accuracy', alpha=0.8)\n",
    "plt.bar(x - 0.5*width, df_resultados['Precision'], width, label='Precision', alpha=0.8)\n",
    "plt.bar(x + 0.5*width, df_resultados['Recall'], width, label='Recall', alpha=0.8)\n",
    "plt.bar(x + 1.5*width, df_resultados['F1-Score'], width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Comparaci√≥n de Modelos de Clasificaci√≥n', fontweight='bold')\n",
    "plt.xticks(x, df_resultados['Modelo'], rotation=45, ha='right')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir el mejor modelo basado en F1-Score\n",
    "mejor_modelo = max(resultados, key=lambda x: x['F1-Score'])\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MEJOR MODELO SEG√öN F1-SCORE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nModelo: {mejor_modelo['Modelo']}\")\n",
    "print(f\"Accuracy: {mejor_modelo['Accuracy']:.4f}\")\n",
    "print(f\"Precision: {mejor_modelo['Precision']:.4f}\")\n",
    "print(f\"Recall: {mejor_modelo['Recall']:.4f}\")\n",
    "print(f\"F1-Score: {mejor_modelo['F1-Score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8747fd22",
   "metadata": {},
   "source": [
    "## 15. Conclusiones\n",
    "\n",
    "### ‚úì Lo que aprendimos:\n",
    "1. **Cargar datasets reales** incluidos en Scikit-Learn\n",
    "2. **Implementar clasificaci√≥n** con Random Forest\n",
    "3. **Evaluar clasificadores** usando m√∫ltiples m√©tricas\n",
    "4. **Interpretar matrices de confusi√≥n** para entender errores\n",
    "5. **Analizar importancia de caracter√≠sticas**\n",
    "6. **Calcular probabilidades** de predicci√≥n\n",
    "7. **Validaci√≥n cruzada** para evaluaci√≥n robusta\n",
    "8. **Comparar diferentes algoritmos**\n",
    "\n",
    "### üìä Resultados clave:\n",
    "- El modelo Random Forest logra excelente accuracy en este dataset\n",
    "- Las caracter√≠sticas de p√©talos son m√°s importantes que las de s√©palos\n",
    "- La matriz de confusi√≥n muestra d√≥nde ocurren los errores\n",
    "- La validaci√≥n cruzada confirma la robustez del modelo\n",
    "\n",
    "### üéØ Aplicaciones reales:\n",
    "Este tipo de clasificaci√≥n se usa en:\n",
    "- **Medicina**: Diagn√≥stico de enfermedades\n",
    "- **Finanzas**: Clasificaci√≥n de riesgo crediticio\n",
    "- **Marketing**: Segmentaci√≥n de clientes\n",
    "- **Manufactura**: Control de calidad\n",
    "- **Biolog√≠a**: Clasificaci√≥n de especies\n",
    "\n",
    "### üí° Pr√≥ximos pasos:\n",
    "- Probar con datasets desbalanceados\n",
    "- Explorar t√©cnicas de feature engineering\n",
    "- Aplicar ensemble methods m√°s avanzados\n",
    "- Optimizar hiperpar√°metros con GridSearchCV\n",
    "- Trabajar con datos del mundo real (Kaggle)\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Referencias\n",
    "- Dataset Iris: Fisher, R.A. (1936). \"The use of multiple measurements in taxonomic problems\"\n",
    "- Documentaci√≥n Scikit-Learn: https://scikit-learn.org/stable/modules/ensemble.html\n",
    "- Random Forest: Breiman, L. (2001). \"Random Forests\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
